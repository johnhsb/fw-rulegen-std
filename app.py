#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MLê¸°ë°˜ ë°©í™”ë²½ ì •ì±… ì¶”ì²œ ì‹œìŠ¤í…œ - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
--------------------------------------------------
ë°©í™”ë²½ ë¡œê·¸ ë¶„ì„ ë° ì •ì±… ì¶”ì²œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import os
import sys
import logging
import json
import hashlib
import ipaddress
import pandas as pd
from datetime import datetime, timedelta
from functools import wraps
from flask import Flask, render_template, request, jsonify, redirect, url_for, session, send_file, make_response, abort
from flask_session import Session
from gevent.pywsgi import WSGIServer
import ssl

# ëª¨ë“ˆ ì„í¬íŠ¸
from modules.auth import load_user_config, hash_password, login_required
from modules.log_parser import LogParser
from modules.traffic_analyzer import TrafficAnalyzer
from modules.policy_generator import PolicyGenerator
from modules.syslog_server import SyslogServer
from config.config import Config, load_system_settings, save_system_settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("firewall_recommender.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("firewall-policy-recommender")

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
app.config.from_object(Config)
Session(app)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬
global_state = {
    'analyzer': None,        # íŠ¸ë˜í”½ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
    'log_df': None,          # ë¡œê·¸ ë°ì´í„°í”„ë ˆì„
    'policies': [],          # ìƒì„±ëœ ì •ì±…
    'config': [],            # ìƒì„±ëœ ì£¼ë‹ˆí¼ ì„¤ì •
    'syslog_server': None,   # Syslog ì„œë²„ ì¸ìŠ¤í„´ìŠ¤
    'is_syslog_running': False,  # Syslog ì„œë²„ ì‹¤í–‰ ìƒíƒœ
    'syslog_config': {       # Syslog ì„œë²„ ì„¤ì •
        'host': '0.0.0.0',
        'port': 514,
        'interval': 3600,
        'device_filter': '',
        'device_filter_type': 'all',
        'regex_filter': '',
        'regex_filter_type': 'include'
    },
    'dbscan_params': {       # DBSCAN íŒŒë¼ë¯¸í„° ì„¤ì •
        'min_occurrences': 1,
        'eps': 0.5,
        'min_samples': 2,
        'max_data_points': 10000
    }
}

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
for directory in [Config.UPLOAD_DIR, Config.OUTPUT_DIR, Config.LOGS_DIR]:
    os.makedirs(directory, exist_ok=True)

# ì €ì¥ëœ ì„¤ì • ë¡œë“œ
saved_settings = load_system_settings()

# DBSCAN íŒŒë¼ë¯¸í„° ì ìš©
if 'dbscan_params' in saved_settings:
    global_state['dbscan_params'].update(saved_settings['dbscan_params'])

# Syslog ì„¤ì • ì ìš©
if 'syslog_config' in saved_settings:
    global_state['syslog_config'].update(saved_settings['syslog_config'])
    
# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • ì ìš©
if 'output_dir' in saved_settings:
    Config.OUTPUT_DIR = saved_settings['output_dir']

# ì‚¬ìš©ì ëª©ë¡ ë¡œë“œ
users = load_user_config(Config.USERS_CONFIG)

#----- ë¼ìš°íŠ¸ ì •ì˜ -----#

@app.route('/')
@login_required
def index():
    """ëŒ€ì‹œë³´ë“œ ë©”ì¸ í˜ì´ì§€"""
    # ë¶„ì„ ê²°ê³¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    manual_analyses = get_analyses_list('upload')
    syslog_analyses = get_analyses_list('syslog')
    
    # ë¡œê·¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    manual_logs = get_logs_list('upload')
    syslog_logs = get_logs_list('syslog')
    
    return render_template('index.html',
                          is_analyzed=global_state['analyzer'] is not None,
                          is_syslog_running=global_state['is_syslog_running'],
                          manual_analyses=manual_analyses,
                          syslog_analyses=syslog_analyses,
                          manual_logs=manual_logs,
                          syslog_logs=syslog_logs)

@app.route('/login', methods=['GET', 'POST'])
def login():
    """ë¡œê·¸ì¸ í˜ì´ì§€"""
    error = None
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        
        # ì‚¬ìš©ì í™•ì¸
        if username in users and users[username] == hash_password(password):
            session['logged_in'] = True
            session['username'] = username
            next_page = request.args.get('next')
            return redirect(next_page or url_for('index'))
        else:
            error = 'ì˜ëª»ëœ ì‚¬ìš©ì ì´ë¦„ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ì…ë‹ˆë‹¤.'
    
    return render_template('login.html', error=error)

@app.route('/logout')
def logout():
    """ë¡œê·¸ì•„ì›ƒ ì²˜ë¦¬"""
    session.pop('logged_in', None)
    session.pop('username', None)
    return redirect(url_for('login'))

@app.route('/upload', methods=['GET', 'POST'])
@login_required
def upload_logs():
    """ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
    if request.method == 'POST':
        if 'logfile' not in request.files:
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 400
        
        uploaded_files = request.files.getlist('logfile')
        if not uploaded_files or uploaded_files[0].filename == '':
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 400
        
        # ê¸°ì¡´ ì—…ë¡œë“œ ì œê±°
        for file in os.listdir(Config.UPLOAD_DIR):
            os.remove(os.path.join(Config.UPLOAD_DIR, file))
        
        # ìƒˆ íŒŒì¼ ì €ì¥
        file_paths = []
        for file in uploaded_files:
            file_path = os.path.join(Config.UPLOAD_DIR, file.filename)
            file.save(file_path)
            file_paths.append(file_path)
        
        session['uploaded_files'] = file_paths
        return jsonify({'success': True, 'files': file_paths})
    
    return render_template('upload.html')

@app.route('/analyze', methods=['GET'])
@login_required
def analyze_logs():
    """ë¡œê·¸ ë¶„ì„ ì‹¤í–‰"""
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ íŠ¹ì • ë¶„ì„ ê²°ê³¼ ë³´ê¸°
    timestamp = request.args.get('timestamp')
    if timestamp:
        # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì¡´ì¬ í™•ì¸
        analysis_result = load_analysis_result(timestamp)
        if not analysis_result:
            logger.warning(f"ìš”ì²­ëœ íƒ€ì„ìŠ¤íƒ¬í”„ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì—†ìŒ: {timestamp}")
            flash('ìš”ì²­í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'warning')
            return redirect(url_for('index'))
            
        # ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì°¾ê¸° ë° í‘œì‹œ
        return render_template('analyze.html', 
                              timestamp=timestamp,
                              params=global_state['dbscan_params'])
        
    # ì¼ë°˜ ë¶„ì„ í˜ì´ì§€
    return render_template('analyze.html', params=global_state['dbscan_params'])

@app.route('/api/analyze', methods=['POST'])
@login_required
def api_analyze_logs():
    """ë¡œê·¸ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸"""
    # ë¶„ì„ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    params = {
        'min_occurrences': int(request.form.get('min_occurrences', 1)),
        'eps': float(request.form.get('eps', 0.5)),
        'min_samples': int(request.form.get('min_samples', 2)),
        'max_data_points': int(request.form.get('max_data_points', 10000))
    }

    # í•„í„° íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    filters = get_filter_params_from_request(request.form)
    top_n = int(request.form.get('top_n', 50))
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ í™•ì¸ - ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì¬ë¶„ì„ ì—¬ë¶€ í™•ì¸
    previous_timestamp = request.form.get('timestamp')
    
    # ë¶„ì„ íƒ€ì… ê²°ì • ë¡œì§
    analysis_type = 'manual'  # ê¸°ë³¸ê°’: ìˆ˜ë™ ë¶„ì„
    source_type = 'upload'    # ê¸°ë³¸ê°’: ì—…ë¡œë“œ
    original_analysis_type = None
    source_filename = None
    
    # ë¡œê·¸ íŒŒì¼ ëª©ë¡ ì´ˆê¸°í™”
    log_files = []
    
    if previous_timestamp:
        logger.info(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼({previous_timestamp})ì— ìƒˆ í•„í„° ì ìš© ì‹œë„")
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì—ì„œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        analysis_result = load_analysis_result(previous_timestamp)
        
        if analysis_result:
            # ì›ë³¸ ë¶„ì„ íƒ€ì… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            original_analysis_type = analysis_result.get('analysis_type', 'auto')
            source_type = analysis_result.get('source', 'upload')
            source_filename = analysis_result.get('source_filename', '')
            log_files = analysis_result.get('log_files', [])
            
            # ì¬ë¶„ì„ íƒ€ì… ê²°ì •
            if original_analysis_type == 'single_file':
                analysis_type = 'single_file_reanalysis'  # ê°œë³„íŒŒì¼ ì¬ë¶„ì„
            elif original_analysis_type == 'auto':
                analysis_type = 'auto_reanalysis'  # ìë™ë¶„ì„ ì¬ë¶„ì„
            else:
                analysis_type = 'manual_reanalysis'  # ìˆ˜ë™ë¶„ì„ ì¬ë¶„ì„
            
            # ëª¨ë“  ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            all_files_exist = all(os.path.exists(file_path) for file_path in log_files)
            
            if not all_files_exist:
                missing_files = [file_path for file_path in log_files if not os.path.exists(file_path)]
                logger.warning(f"ì¼ë¶€ ì›ë³¸ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing_files}")
                
                if source_type == 'upload':
                    return jsonify({'error': 'ì›ë³¸ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.'}), 400
                else:  # syslog
                    return jsonify({'error': 'ì›ë³¸ Syslog íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë¡œê·¸ê°€ ìˆ˜ì§‘ë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ê±°ë‚˜ ë‹¤ë¥¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì„ íƒí•˜ì„¸ìš”.'}), 400
            
            logger.info(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì—ì„œ {len(log_files)}ê°œì˜ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë¡œë“œ (ì›ë³¸ íƒ€ì…: {original_analysis_type})")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ê±°ë‚˜ í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì˜ ë¡œê·¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°
    if not log_files:
        # ê¸°ì¡´ ë¡œì§: ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸
        uploaded_files = session.get('uploaded_files', [])
        
        if not uploaded_files:
            return jsonify({'error': 'ë¡œê·¸ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”'}), 400
            
        log_files = uploaded_files
        analysis_type = 'manual'  # ìƒˆë¡œìš´ ìˆ˜ë™ ë¶„ì„
        source_type = 'upload'
        logger.info(f"ì„¸ì…˜ì—ì„œ {len(log_files)}ê°œì˜ ì—…ë¡œë“œëœ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë¡œë“œ")

    try:
        # ë¡œê·¸ íŒŒì‹±
        parser = LogParser(log_files=log_files)
        log_df = parser.process_logs()

        if log_df.empty:
            return jsonify({'error': 'ìœ íš¨í•œ ë¡œê·¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400

        # í•„í„°ë§ ì ìš©
        filtered_df = apply_filters(log_df, filters)

        if filtered_df.empty:
            return jsonify({'error': 'í•„í„°ë§ í›„ ë‚¨ì€ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ì£¼ì„¸ìš”.'}), 400

        # íŠ¸ë˜í”½ ë¶„ì„
        analyzer = TrafficAnalyzer(filtered_df, **params)
        analyzer.cluster_traffic_patterns()

        # ë¶„ì„ ê²°ê³¼ ìƒì„±
        top_traffic_df = analyzer.analyze_top_traffic_patterns(top_n=top_n, subnet_grouping='/32')
        policies = analyzer.generate_policy_recommendations()
        config = PolicyGenerator(policies).generate_juniper_config()

        # ì‹œê°í™” ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        visualizations = create_visualizations(analyzer, timestamp)

        # ì¥ë¹„ëª… ì •ë³´ ìˆ˜ì§‘ - ë¡œê·¸ ë‚´ìš©ì—ì„œë§Œ ì¶”ì¶œ
        device_names = []
        if 'device_name' in filtered_df.columns:
            log_device_names = list(filtered_df['device_name'].unique())
            # 'unknown'ì´ ì•„ë‹Œ ìœ íš¨í•œ ì¥ë¹„ëª…ë§Œ í•„í„°ë§
            device_names = [name for name in log_device_names if name and name.strip() != 'unknown']

        # ì¥ë¹„ëª…ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not device_names:
            device_names = ['Unknown_Device']
            logger.warning(f"ë¡œê·¸ì—ì„œ ìœ íš¨í•œ ì¥ë¹„ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ íƒ€ì…: {analysis_type}")

        logger.info(f"ì¼ë°˜ ë¶„ì„ - ë¡œê·¸ì—ì„œ ì¶”ì¶œëœ ì¥ë¹„ëª…: {device_names}")
        
        # í•„í„° ì ìš© ì—¬ë¶€ í™•ì¸
        filters_applied = any([
            filters.get('device_name_filter') and filters.get('device_name_filter').strip(),
            filters.get('source_ip_filter') and filters.get('source_ip_filter').strip(),
            filters.get('destination_ip_filter') and filters.get('destination_ip_filter').strip(),
            filters.get('port_filter') and filters.get('port_filter').strip(),
            filters.get('protocol_filter') and filters.get('protocol_filter').strip(),
            filters.get('source_zone_filter') and filters.get('source_zone_filter').strip(),
            filters.get('destination_zone_filter') and filters.get('destination_zone_filter').strip(),
            filters.get('exclude_noise')
        ])

        # ë¡œê·¸ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œì™¸)
        log_filenames = [os.path.basename(f) for f in log_files]

        # ë¶„ì„ ê²°ê³¼ ì €ì¥ - analysis_type í¬í•¨
        save_analysis_results(timestamp, {
            'params': params,
            'filters': filters,
            'policies': policies,
            'config': config,
            'top_traffic': top_traffic_df.to_dict('records') if top_traffic_df is not None else [],
            'visualizations': visualizations,
            'source': source_type,
            'log_files': log_files,
            'log_filenames': log_filenames,
            'device_names': device_names,
            'filters_applied': filters_applied,
            'total_log_records': len(log_df),
            'filtered_log_records': len(filtered_df),
            'analysis_type': analysis_type,  # ì˜¬ë°”ë¥¸ ë¶„ì„ íƒ€ì… ì„¤ì •
            'original_analysis_type': original_analysis_type,  # ì›ë³¸ ë¶„ì„ íƒ€ì… ë³´ì¡´
            'source_filename': source_filename,  # ì›ë³¸ íŒŒì¼ëª… ë³´ì¡´ (ê°œë³„íŒŒì¼ ë¶„ì„ì˜ ê²½ìš°)
            'is_reanalysis': previous_timestamp is not None,  # ì¬ë¶„ì„ ì—¬ë¶€
            'previous_timestamp': previous_timestamp  # ì›ë³¸ ë¶„ì„ íƒ€ì„ìŠ¤íƒ¬í”„
        })

        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        global_state['analyzer'] = analyzer
        global_state['log_df'] = filtered_df
        global_state['policies'] = policies
        global_state['config'] = config

        return jsonify({
            'success': True,
            'policies_count': len(policies),
            'timestamp': timestamp,
            'visualizations': visualizations,
            'analysis_type': analysis_type
        })

    except Exception as e:
        logger.error(f"API ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/api/analysis_data')
@login_required
def api_analysis_data():
    """íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    timestamp = request.args.get('timestamp')
    if not timestamp:
        return jsonify({'error': 'íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ í•´ë‹¹í•˜ëŠ” ë¶„ì„ íŒŒì¼ ê²€ìƒ‰
    analysis_file = None
    for filename in os.listdir(Config.OUTPUT_DIR):
        if filename.startswith('analysis_') and filename.endswith('.json'):
            # íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ë¶€ë¶„ ì¶”ì¶œ
            file_parts = filename.replace('analysis_', '').replace('.json', '').split('_')
            if len(file_parts) >= 3:  # [ì¥ë¹„ëª…, ë‚ ì§œ, ì‹œê°„] í˜•íƒœ
                file_timestamp = f"{file_parts[-2]}_{file_parts[-1]}"
                if file_timestamp == timestamp:
                    analysis_file = os.path.join(Config.OUTPUT_DIR, filename)
                    break
    
    if not analysis_file:
        return jsonify({'error': 'í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    try:
        with open(analysis_file, 'r') as f:
            analysis_data = json.load(f)
        return jsonify(analysis_data)
    except Exception as e:
        logger.error(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'}), 500

@app.route('/policies')
@login_required
def view_policies():
    """ì •ì±… ì¶”ì²œ ë³´ê¸°"""
    timestamp = request.args.get('timestamp')
    
    if timestamp:
        # íŠ¹ì • ë¶„ì„ì˜ ì •ì±… ë¶ˆëŸ¬ì˜¤ê¸°
        analysis = load_analysis_result(timestamp)
        if analysis and 'policies' in analysis:
            return render_template('policies.html', 
                                  policies=analysis['policies'],
                                  timestamp=timestamp)
    
    # í˜„ì¬ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if global_state['policies']:
        return render_template('policies.html', 
                              policies=global_state['policies'])
    
    # ì •ì±…ì´ ì—†ì„ ê²½ìš° ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë””ë ‰ì…˜
    return redirect(url_for('index'))

@app.route('/config')
@login_required
def view_config():
    """ìƒì„±ëœ Juniper ì„¤ì • ë³´ê¸°"""
    timestamp = request.args.get('timestamp')
    
    if timestamp:
        # íŠ¹ì • ë¶„ì„ì˜ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        analysis = load_analysis_result(timestamp)
        if analysis and 'config' in analysis:
            return render_template('config.html', 
                                  config=analysis['config'],
                                  timestamp=timestamp)
    
    # í˜„ì¬ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if global_state['config']:
        return render_template('config.html', 
                              config=global_state['config'])
    
    # ì„¤ì •ì´ ì—†ì„ ê²½ìš° ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë””ë ‰ì…˜
    return redirect(url_for('index'))

@app.route('/syslog', methods=['GET', 'POST'])
@login_required
def manage_syslog():
    """Syslog ì„œë²„ ê´€ë¦¬"""
    if request.method == 'POST':
        action = request.form.get('action')
        
        if action == 'start':
            # ì„œë²„ ì‹œì‘
            try:
                if global_state['is_syslog_running']:
                    return jsonify({'error': 'Syslog ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤'}), 400
                
                # ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                host = request.form.get('host', '0.0.0.0')
                port = int(request.form.get('port', 514))
                interval = int(request.form.get('interval', 3600))
                device_filter = request.form.get('device_filter', '')
                device_filter_type = request.form.get('device_filter_type', 'all')
                regex_filter = request.form.get('regex_filter', '')
                regex_filter_type = request.form.get('regex_filter_type', 'include')
                
                # ì„¤ì • ì €ì¥
                global_state['syslog_config'].update({
                    'host': host,
                    'port': port,
                    'interval': interval,
                    'device_filter': device_filter,
                    'device_filter_type': device_filter_type,
                    'regex_filter': regex_filter,
                    'regex_filter_type': regex_filter_type
                })
                
                # ì„¤ì • ì˜êµ¬ ì €ì¥
                settings_dict = {
                    'dbscan_params': global_state['dbscan_params'],
                    'output_dir': Config.OUTPUT_DIR,
                    'syslog_config': global_state['syslog_config']
                }
                save_system_settings(settings_dict)
                
                # Syslog ì„œë²„ ì‹œì‘
                start_syslog_server()
                
                return jsonify({'success': True})
            except Exception as e:
                logger.error(f"Syslog server error: {e}")
                return jsonify({'error': f'Syslog ì„œë²„ ì˜¤ë¥˜: {str(e)}'}), 500

        elif action == 'stop':
            # ì„œë²„ ì¤‘ì§€
            if not global_state['is_syslog_running']:
                return jsonify({'error': 'Syslog ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤'}), 400

            stop_syslog_server()
            return jsonify({'success': True})

    # GET ë©”ì„œë“œëŠ” ì„¤ì • í˜ì´ì§€ í‘œì‹œ
    return render_template('syslog.html',
                          is_running=global_state['is_syslog_running'],
                          syslog_config=global_state['syslog_config'])

@app.route('/api/log_files')
@login_required
def api_log_files():
    """ë¡œê·¸ íŒŒì¼ ëª©ë¡ API"""
    log_type = request.args.get('type', 'upload')

    # ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
    logs = get_logs_list(log_type)

    # ì‘ë‹µ í˜•íƒœ ë§ì¶”ê¸°
    files = []
    for log in logs:
        files.append({
            'filename': log['filename'],
            'size': log['size'],
            'modified': log['modified'].isoformat() if hasattr(log['modified'], 'isoformat') else str(log['modified'])
        })

    return jsonify({
        'success': True,
        'files': files
    })

@app.route('/api/system_logs')
@login_required
def api_system_logs():
    """ì‹œìŠ¤í…œ ë¡œê·¸ íŒŒì¼ ë‚´ìš© ë°˜í™˜ API"""
    try:
        # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        log_file = "firewall_recommender.log"

        # í‘œì‹œí•  ìµœëŒ€ ë¼ì¸ ìˆ˜ (ì˜µì…˜ìœ¼ë¡œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì„ ìˆ˜ ìˆìŒ)
        max_lines = request.args.get('max_lines', 50, type=int)

        # ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(log_file):
            return jsonify({'error': 'ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        # íŒŒì¼ì˜ ë§ˆì§€ë§‰ N ë¼ì¸ ì½ê¸° (tail ê¸°ëŠ¥)
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
            # ë§ˆì§€ë§‰ max_lines ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸°
            log_content = lines[-max_lines:] if len(lines) > max_lines else lines

        return jsonify({'success': True, 'log_content': log_content})

    except Exception as e:
        logger.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({'error': f'ë¡œê·¸ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/settings', methods=['GET', 'POST'])
@login_required
def settings():
    """ì‹œìŠ¤í…œ ì„¤ì •"""
    if request.method == 'POST':
        try:
            # DBSCAN íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            global_state['dbscan_params'].update({
                'min_occurrences': int(request.form.get('min_occurrences', 1)),
                'eps': float(request.form.get('eps', 0.5)),
                'min_samples': int(request.form.get('min_samples', 2)),
                'max_data_points': int(request.form.get('max_data_points', 10000))
            })

            # Syslog ì„¤ì • ì—…ë°ì´íŠ¸
            global_state['syslog_config'].update({
                'host': request.form.get('syslog_host', global_state['syslog_config']['host']),
                'port': int(request.form.get('syslog_port', global_state['syslog_config']['port'])),
                'interval': int(request.form.get('syslog_interval', global_state['syslog_config']['interval']))
            })
            
            # ê¸°íƒ€ ì„¤ì • ì—…ë°ì´íŠ¸ (ë””ë ‰í† ë¦¬ ë“±)
            Config.OUTPUT_DIR = request.form.get('output_dir', Config.OUTPUT_DIR)
            retention_days = int(request.form.get('retention_days', 30))
            
            # ì„¤ì • ì €ì¥ - Syslog ì„¤ì •ë„ í•¨ê»˜ ì €ì¥
            settings_dict = {
                'dbscan_params': global_state['dbscan_params'],
                'output_dir': Config.OUTPUT_DIR,
                'retention_days': retention_days,
                'syslog_config': global_state['syslog_config']
            }
            
            save_system_settings(settings_dict)
            
            return jsonify({'success': True})
        except Exception as e:
            return jsonify({'error': str(e)}), 400
    
    # GET ë©”ì„œë“œëŠ” ì„¤ì • í˜ì´ì§€ í‘œì‹œ
    return render_template('settings.html',
                          dbscan_params=global_state['dbscan_params'],
                          output_dir=Config.OUTPUT_DIR,
                          syslog_config=global_state['syslog_config'])

@app.route('/api/system_info')
@login_required
def api_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
    import psutil
    
    try:
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
        disk_usage = psutil.disk_usage(Config.BASE_DIR)
        disk_usage_str = f"{disk_usage.used / (1024**3):.1f}GB / {disk_usage.total / (1024**3):.1f}GB ({disk_usage.percent}%)"
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory = psutil.virtual_memory()
        memory_usage_str = f"{memory.used / (1024**3):.1f}GB / {memory.total / (1024**3):.1f}GB ({memory.percent}%)"
        
        return jsonify({
            'success': True,
            'disk_usage': disk_usage_str,
            'memory_usage': memory_usage_str
        })
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/cleanup', methods=['POST'])
@login_required
def api_cleanup():
    """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
    try:
        retention_days = int(request.form.get('retention_days', 30))
        if retention_days < 1:
            return jsonify({'success': False, 'error': 'ë³´ê´€ ì¼ìˆ˜ëŠ” 1ì¼ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤'})
        
        # íŒŒì¼ ì •ë¦¬ ë¡œì§ êµ¬í˜„
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        deleted_count = 0
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ë¦¬
        for filename in os.listdir(Config.OUTPUT_DIR):
            file_path = os.path.join(Config.OUTPUT_DIR, filename)
            if os.path.isfile(file_path):
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_mtime < cutoff_date:
                    os.remove(file_path)
                    deleted_count += 1
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì •ë¦¬
        for filename in os.listdir(Config.LOGS_DIR):
            file_path = os.path.join(Config.LOGS_DIR, filename)
            if os.path.isfile(file_path):
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if file_mtime < cutoff_date:
                    os.remove(file_path)
                    deleted_count += 1
        
        return jsonify({
            'success': True,
            'message': f'{deleted_count}ê°œì˜ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
    except Exception as e:
        logger.error(f"ë°ì´í„° ì •ë¦¬ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/analyze_syslog_file', methods=['POST'])
@login_required
def api_analyze_syslog_file():
    """ê°œë³„ Syslog íŒŒì¼ ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸"""
    filename = request.form.get('filename')
    
    if not filename:
        return jsonify({'error': 'íŒŒì¼ëª…ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}), 400
    
    # íŒŒì¼ ê²½ë¡œ êµ¬ì„±
    log_file_path = os.path.join(Config.LOGS_DIR, filename)
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(log_file_path):
        return jsonify({'error': 'ì§€ì •ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
    
    # ë¶„ì„ íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    params = {
        'min_occurrences': int(request.form.get('min_occurrences', 1)),
        'eps': float(request.form.get('eps', 0.5)),
        'min_samples': int(request.form.get('min_samples', 2)),
        'max_data_points': int(request.form.get('max_data_points', 10000))
    }

    # í•„í„° íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    filters = get_filter_params_from_request(request.form)

    # top_n íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    top_n = int(request.form.get('top_n', 50))

    try:
        # ë¡œê·¸ íŒŒì‹±
        parser = LogParser(log_files=[log_file_path])
        log_df = parser.process_logs()

        if log_df.empty:
            return jsonify({'error': 'ìœ íš¨í•œ ë¡œê·¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400

        # í•„í„°ë§ ì ìš©
        filtered_df = apply_filters(log_df, filters)

        if filtered_df.empty:
            return jsonify({'error': 'í•„í„°ë§ í›„ ë‚¨ì€ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ì£¼ì„¸ìš”.'}), 400

        # íŠ¸ë˜í”½ ë¶„ì„
        analyzer = TrafficAnalyzer(filtered_df, **params)
        analyzer.cluster_traffic_patterns()

        # ë¶„ì„ ê²°ê³¼ (ìƒìœ„ íŠ¸ë˜í”½ íŒ¨í„´, í´ëŸ¬ìŠ¤í„°ë§ ë“±)
        top_traffic_df = analyzer.analyze_top_traffic_patterns(top_n=top_n, subnet_grouping='/32')
        policies = analyzer.generate_policy_recommendations()
        config = PolicyGenerator(policies).generate_juniper_config()

        # ì‹œê°í™” ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        visualizations = create_visualizations(analyzer, timestamp)

        # ì¥ë¹„ëª… ì •ë³´ ìˆ˜ì§‘ - ë¡œê·¸ ë‚´ìš©ì—ì„œë§Œ ì¶”ì¶œ
        device_names = []
        if 'device_name' in filtered_df.columns:
            log_device_names = list(filtered_df['device_name'].unique())
            # 'unknown'ì´ ì•„ë‹Œ ìœ íš¨í•œ ì¥ë¹„ëª…ë§Œ í•„í„°ë§
            device_names = [name for name in log_device_names if name and name.strip() != 'unknown']
        
        # ì¥ë¹„ëª…ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not device_names:
            device_names = ['Unknown_Device']
            logger.warning(f"ë¡œê·¸ì—ì„œ ìœ íš¨í•œ ì¥ë¹„ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼: {filename}")
        
        logger.info(f"ë‹¨ì¼ íŒŒì¼ ë¶„ì„ - ë¡œê·¸ì—ì„œ ì¶”ì¶œëœ ì¥ë¹„ëª…: {device_names}")

        # í•„í„° ì ìš© ì—¬ë¶€ í™•ì¸
        filters_applied = any([
            filters.get('device_name_filter') and filters.get('device_name_filter').strip(),
            filters.get('source_ip_filter') and filters.get('source_ip_filter').strip(),
            filters.get('destination_ip_filter') and filters.get('destination_ip_filter').strip(),
            filters.get('port_filter') and filters.get('port_filter').strip(),
            filters.get('protocol_filter') and filters.get('protocol_filter').strip(),
            filters.get('source_zone_filter') and filters.get('source_zone_filter').strip(),
            filters.get('destination_zone_filter') and filters.get('destination_zone_filter').strip(),
            filters.get('exclude_noise')
        ])

        # ë¡œê·¸ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ì œì™¸)
        log_filenames = [filename]

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        save_analysis_results(timestamp, {
            'params': params,
            'filters': filters,
            'policies': policies,
            'config': config,
            'top_traffic': top_traffic_df.to_dict('records') if top_traffic_df is not None else [],
            'visualizations': visualizations,
            'source': 'syslog',
            'log_files': [log_file_path],
            'log_filenames': log_filenames,
            'device_names': device_names,  # ë¡œê·¸ì—ì„œë§Œ ì¶”ì¶œëœ ì¥ë¹„ëª…
            'filters_applied': filters_applied,
            'total_log_records': len(log_df),
            'filtered_log_records': len(filtered_df),
            'analysis_type': 'single_file',
            'source_filename': filename
        })

        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸
        global_state['analyzer'] = analyzer
        global_state['log_df'] = filtered_df
        global_state['policies'] = policies
        global_state['config'] = config

        logger.info(f"ë‹¨ì¼ Syslog íŒŒì¼ ë¶„ì„ ì™„ë£Œ: {filename} -> {len(policies)}ê°œ ì •ì±… ìƒì„±")

        return jsonify({
            'success': True,
            'policies_count': len(policies),
            'timestamp': timestamp,
            'visualizations': visualizations,
            'filename': filename,
            'device_names': device_names,
            'message': f'íŒŒì¼ "{filename}" ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
        })

    except Exception as e:
        logger.error(f"ë‹¨ì¼ Syslog íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/visualization/<path:filename>')
def serve_visualization(filename):
    """ì‹œê°í™” íŒŒì¼ ì œê³µ (êµ­ê°€ë³„, ASNë³„ í¬í•¨)"""
    # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ êµ¬ì„±
    full_path = os.path.join(Config.OUTPUT_DIR, filename)
    
    # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ê·¸ëŒ€ë¡œ ì „ì†¡
    if os.path.exists(full_path):
        return send_file(full_path)
    
    # ë™ì  HTML ìƒì„±ì„ ìœ„í•œ ì •ë³´ ì¶”ì¶œ
    viz_type = "ë°ì´í„° ì‹œê°í™”"
    ip_version = "IPv4"
    analysis_type = "ì¼ë°˜"
    
    # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
    if '_ipv6.html' in filename:
        ip_version = "IPv6"
    
    if 'sankey_country' in filename:
        viz_type = "êµ­ê°€ë³„ íŠ¸ë˜í”½ íë¦„"
        analysis_type = "êµ­ê°€ë³„"
    elif 'sankey_asn' in filename:
        viz_type = "ASNë³„ íŠ¸ë˜í”½ íë¦„"  
        analysis_type = "ASNë³„"
    elif 'sankey' in filename:
        viz_type = "Sankey ë‹¤ì´ì–´ê·¸ë¨"
        analysis_type = "IPë³„"
    elif '3d_interactive' in filename:
        viz_type = "3D íŠ¸ë˜í”½ ì‹œê°í™”"
        analysis_type = "3D"
    
    # ë™ì  HTML ìƒì„±
    html_content = f"""
    <!DOCTYPE html>
    <html lang="ko" data-bs-theme="dark">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{ip_version} {analysis_type} ë¶„ì„ - ë°ì´í„° ì—†ìŒ</title>
        <link rel="stylesheet" href="/static/css/bootstrap.min.css">
        <link rel="stylesheet" href="/static/css/bootstrap-icons.css">
        <style>
            body {{
                background-color: #121212 !important;
                color: #e0e0e0;
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            }}
            .card {{
                background-color: #1e1e1e;
                border-color: #333;
                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);
            }}
            .card-header {{
                background: linear-gradient(135deg, #1a1a2e, #16213e);
                border-bottom-color: #333;
            }}
            .info-icon {{
                font-size: 64px;
                background: linear-gradient(135deg, #667eea, #764ba2);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
            }}
            .feature-badge {{
                background: linear-gradient(135deg, #667eea, #764ba2);
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 20px;
                font-weight: 500;
                font-size: 0.9rem;
            }}
            .suggestion-list {{
                background-color: #1a1a1a;
                border-radius: 8px;
                padding: 20px;
                margin-top: 20px;
            }}
            .suggestion-item {{
                display: flex;
                align-items: center;
                margin-bottom: 12px;
                padding: 8px;
                border-radius: 6px;
                transition: background-color 0.2s;
            }}
            .suggestion-item:hover {{
                background-color: #2d2d2d;
            }}
            .suggestion-icon {{
                margin-right: 12px;
                color: #667eea;
            }}
        </style>
    </head>
    <body class="d-flex justify-content-center align-items-center" style="min-height: 100vh; padding: 20px;">
        <div class="container" style="max-width: 600px;">
            <div class="card shadow-lg">
                <div class="card-header text-center">
                    <h4 class="mb-0 text-white">
                        <i class="bi bi-{"globe" if "country" in analysis_type.lower() else "building" if "asn" in analysis_type.lower() else "diagram-3"} me-2"></i>
                        {ip_version} {viz_type}
                    </h4>
                    <span class="feature-badge mt-2">
                        {"ğŸŒ GeoIP ê¸°ë°˜" if analysis_type in ["êµ­ê°€ë³„", "ASNë³„"] else "ğŸ“Š íŠ¸ë˜í”½ ë¶„ì„"}
                    </span>
                </div>
                <div class="card-body text-center p-4">
                    <div class="info-icon mb-3">
                        <i class="bi bi-info-circle"></i>
                    </div>
                    <h5 class="mb-3">{ip_version} {analysis_type} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤</h5>
                    
                    <div class="alert alert-info border-0" style="background-color: rgba(13, 202, 240, 0.1); border-left: 4px solid #0dcaf0;">
                        <p class="mb-2">í˜„ì¬ ë¶„ì„ ê²°ê³¼ì—ëŠ” {ip_version} {analysis_type} íŠ¸ë˜í”½ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
                        <small class="text-muted">
                            {"ë‹¤ë¥¸ IP ë²„ì „ì˜ ë°ì´í„°ë§Œ ìˆê±°ë‚˜ í•´ë‹¹ íŠ¸ë˜í”½ì´ ë¶„ì„ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤." if ip_version == "IPv6" else "IPv6 íŠ¸ë˜í”½ì´ ì—†ê±°ë‚˜ í•„í„°ë§ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
                        </small>
                    </div>
                    
                    <div class="suggestion-list">
                        <h6 class="text-light mb-3"><i class="bi bi-lightbulb me-2"></i>í•´ê²° ë°©ë²•</h6>
                        
                        <div class="suggestion-item">
                            <i class="bi bi-check-circle suggestion-icon"></i>
                            <span>ë‹¤ë¥¸ IP ë²„ì „ íƒ­ì„ í™•ì¸í•´ë³´ì„¸ìš”</span>
                        </div>
                        
                        <div class="suggestion-item">
                            <i class="bi bi-funnel suggestion-icon"></i>
                            <span>ë¶„ì„ í•„í„° ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”</span>
                        </div>
                        
                        {"<div class='suggestion-item'><i class='bi bi-database suggestion-icon'></i><span>GeoIP ë°ì´í„°ë² ì´ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”</span></div>" if analysis_type in ["êµ­ê°€ë³„", "ASNë³„"] else ""}
                        
                        <div class="suggestion-item">
                            <i class="bi bi-arrow-clockwise suggestion-icon"></i>
                            <span>ìƒˆë¡œìš´ ë¡œê·¸ ë°ì´í„°ë¡œ ë‹¤ì‹œ ë¶„ì„í•´ë³´ì„¸ìš”</span>
                        </div>
                    </div>
                    
                    <div class="mt-4">
                        <button onclick="window.parent.history.back()" class="btn btn-outline-light me-2">
                            <i class="bi bi-arrow-left me-1"></i>ì´ì „ìœ¼ë¡œ
                        </button>
                        <button onclick="window.parent.location.reload()" class="btn btn-primary">
                            <i class="bi bi-arrow-clockwise me-1"></i>ìƒˆë¡œê³ ì¹¨
                        </button>
                    </div>
                </div>
            </div>
        </div>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
    </body>
    </html>
    """
    
    # ì‘ë‹µ ìƒì„± ë° ë°˜í™˜
    response = make_response(html_content)
    response.headers['Content-Type'] = 'text/html; charset=utf-8'
    response.headers['Cache-Control'] = 'max-age=3600'  # 1ì‹œê°„ ìºì‹±
    return response 

@app.route('/api/traffic_patterns', methods=['POST'])
@login_required
def api_traffic_patterns():
    """ì‹¤ì‹œê°„ íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„ API (ì„œë¸Œë„· ê·¸ë£¹í•‘ ì˜µì…˜ ì§€ì›)"""
    try:
        timestamp = request.form.get('timestamp')
        subnet_grouping = request.form.get('subnet_grouping', '/32')
        top_n = int(request.form.get('top_n', 100))
        
        if not timestamp:
            return jsonify({'error': 'íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        analysis_result = load_analysis_result(timestamp)
        if not analysis_result:
            return jsonify({'error': 'í•´ë‹¹ íƒ€ì„ìŠ¤íƒ¬í”„ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 404
        
        # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
        log_files = analysis_result.get('log_files', [])
        if not log_files:
            return jsonify({'error': 'ì›ë³¸ ë¡œê·¸ íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
        existing_files = [f for f in log_files if os.path.exists(f)]
        if not existing_files:
            return jsonify({'error': 'ì›ë³¸ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ê¸°ì¡´ í•„í„° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        filters = analysis_result.get('filters', {})
        
        # ë¡œê·¸ ì¬íŒŒì‹±
        parser = LogParser(log_files=existing_files)
        log_df = parser.process_logs()
        
        if log_df.empty:
            return jsonify({'error': 'ìœ íš¨í•œ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # í•„í„° ì ìš©
        filtered_df = apply_filters(log_df, filters)
        
        if filtered_df.empty:
            return jsonify({'error': 'í•„í„°ë§ í›„ ë‚¨ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400
        
        # ê¸°ì¡´ ë¶„ì„ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        params = analysis_result.get('params', {
            'min_occurrences': 1,
            'eps': 0.5,
            'min_samples': 2,
            'max_data_points': 10000
        })
        
        # íŠ¸ë˜í”½ ë¶„ì„ê¸° ìƒì„±
        analyzer = TrafficAnalyzer(filtered_df, **params)
        analyzer.cluster_traffic_patterns()
        
        # ìƒˆë¡œìš´ ì„œë¸Œë„· ê·¸ë£¹í•‘ìœ¼ë¡œ ìƒìœ„ íŠ¸ë˜í”½ ë¶„ì„
        top_traffic_df = analyzer.analyze_top_traffic_patterns(
            top_n=top_n, 
            subnet_grouping=subnet_grouping
        )
        
        if top_traffic_df is None or top_traffic_df.empty:
            return jsonify({'traffic_patterns': [], 'subnet_grouping': subnet_grouping})
        
        # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        traffic_patterns = top_traffic_df.to_dict('records')
        
        return jsonify({
            'success': True,
            'traffic_patterns': traffic_patterns,
            'subnet_grouping': subnet_grouping,
            'total_patterns': len(traffic_patterns)
        })
        
    except Exception as e:
        logger.error(f"íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„ API ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

#----- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ -----#

def get_filter_params_from_request(form_data):
    """ìš”ì²­ ë°ì´í„°ì—ì„œ í•„í„° íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
    return {
        'device_name_filter': form_data.get('device_name_filter', ''),
        'device_name_filter_type': form_data.get('device_name_filter_type', 'include'),
        'source_ip_filter': form_data.get('source_ip_filter', ''),
        'source_ip_filter_type': form_data.get('source_ip_filter_type', 'include'),
        'destination_ip_filter': form_data.get('destination_ip_filter', ''),
        'destination_ip_filter_type': form_data.get('destination_ip_filter_type', 'include'),
        'port_filter': form_data.get('port_filter', ''),
        'port_filter_type': form_data.get('port_filter_type', 'include'),
        'protocol_filter': form_data.get('protocol_filter', ''),
        'protocol_filter_type': form_data.get('protocol_filter_type', 'include'),
        'source_zone_filter': form_data.get('source_zone_filter', ''),
        'source_zone_filter_type': form_data.get('source_zone_filter_type', 'include'),
        'destination_zone_filter': form_data.get('destination_zone_filter', ''),
        'destination_zone_filter_type': form_data.get('destination_zone_filter_type', 'include'),
        'policy_name_filter': form_data.get('policy_name_filter', ''),  # ì •ì±…ëª… í•„í„° ì¶”ê°€
        'policy_name_filter_type': form_data.get('policy_name_filter_type', 'include'),  # ì •ì±…ëª… í•„í„° íƒ€ì… ì¶”ê°€
        'start_date': form_data.get('start_date', ''),
        'end_date': form_data.get('end_date', ''),
        'exclude_noise': form_data.get('exclude_noise') == '1'
    }

def apply_filters(log_df, filters):
    """í•„í„°ë¥¼ ë¡œê·¸ ë°ì´í„°ì— ì ìš©"""
    filtered_df = log_df.copy()
    
    # IP ì£¼ì†Œ ë§¤ì¹­ í—¬í¼ í•¨ìˆ˜ - CIDR ë° ì •í™•í•œ ë§¤ì¹­ ì§€ì›
    def ip_matches(ip, filter_list):
        try:
            # IPë¥¼ ipaddress ê°ì²´ë¡œ ë³€í™˜
            target_ip = ipaddress.ip_address(ip)
            
            for filter_ip in filter_list:
                if '/' in filter_ip:  # CIDR í‘œê¸°ë²•
                    try:
                        network = ipaddress.ip_network(filter_ip, strict=False)
                        if target_ip in network:
                            return True
                    except ValueError:
                        # ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­ìœ¼ë¡œ í´ë°±
                        if filter_ip == ip:
                            return True
                else:  # ë‹¨ì¼ IP
                    try:
                        filter_ip_obj = ipaddress.ip_address(filter_ip)
                        if target_ip == filter_ip_obj:
                            return True
                    except ValueError:
                        # IP ë³€í™˜ ì˜¤ë¥˜ ì‹œ ì •í™•í•œ ë¬¸ìì—´ ë¹„êµ
                        if filter_ip == ip:
                            return True
            return False
        except ValueError:
            # IP ë³€í™˜ ì˜¤ë¥˜ ì‹œ ì •í™•í•œ ë¬¸ìì—´ ë§¤ì¹­
            return ip in filter_list

    # ì¥ë¹„ëª… í•„í„°
    if filters.get('device_name_filter') and filters.get('device_name_filter').strip():
        device_filter = filters['device_name_filter']
        filter_type = filters['device_name_filter_type']

        device_list = [device.strip() for device in device_filter.split(',') if device.strip()]

        if device_list:
            if filter_type == 'include':
                filtered_df = filtered_df[filtered_df['device_name'].isin(device_list)]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~filtered_df['device_name'].isin(device_list)]

    # ì¶œë°œì§€ IP í•„í„°
    if filters.get('source_ip_filter') and filters.get('source_ip_filter').strip():
        source_ip_filter = filters['source_ip_filter']
        filter_type = filters['source_ip_filter_type']

        ip_list = [ip.strip() for ip in source_ip_filter.split(',') if ip.strip()]

        if ip_list:
            # í–¥ìƒëœ IP ë§¤ì¹­ ì‚¬ìš©
            mask = filtered_df['source_ip'].apply(lambda ip: ip_matches(ip, ip_list))

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # ëª©ì ì§€ IP í•„í„°
    if filters.get('destination_ip_filter') and filters.get('destination_ip_filter').strip():
        dest_ip_filter = filters['destination_ip_filter']
        filter_type = filters['destination_ip_filter_type']

        ip_list = [ip.strip() for ip in dest_ip_filter.split(',') if ip.strip()]

        if ip_list:
            # í–¥ìƒëœ IP ë§¤ì¹­ ì‚¬ìš©
            mask = filtered_df['destination_ip'].apply(lambda ip: ip_matches(ip, ip_list))

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # í¬íŠ¸ í•„í„° - ëŒ€ê·œëª¨ ë²”ìœ„ ì²˜ë¦¬ ê°œì„ 
    if filters.get('port_filter') and filters.get('port_filter').strip():
        port_filter = filters['port_filter']
        filter_type = filters['port_filter_type']

        # í¬íŠ¸ ë²”ìœ„ íš¨ìœ¨ì  ì²˜ë¦¬
        def port_in_ranges(port, port_ranges):
            for p_range in port_ranges:
                if '-' in p_range:
                    start, end = map(int, p_range.split('-'))
                    if start <= port <= end:
                        return True
                else:
                    if port == int(p_range):
                        return True
            return False

        port_ranges = [p.strip() for p in port_filter.split(',') if p.strip()]

        if port_ranges:
            # ë²”ìœ„ ê²€ì‚¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í¬íŠ¸ í™•ì¸
            mask = (
                filtered_df['source_port'].apply(lambda p: port_in_ranges(p, port_ranges)) | 
                filtered_df['destination_port'].apply(lambda p: port_in_ranges(p, port_ranges))
            )

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # í”„ë¡œí† ì½œ í•„í„°
    if filters.get('protocol_filter') and filters.get('protocol_filter').strip():
        protocol_filter = filters['protocol_filter']
        filter_type = filters['protocol_filter_type']

        protocol_list = [p.strip().lower() for p in protocol_filter.split(',') if p.strip()]

        if protocol_list:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì •í™•í•œ í”„ë¡œí† ì½œ ë§¤ì¹­
            mask = filtered_df['protocol'].str.lower().isin(protocol_list)

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # ì •ì±…ëª… í•„í„° ì¶”ê°€
    if filters.get('policy_name_filter'):
        policy_filter = filters['policy_name_filter']
        filter_type = filters['policy_name_filter_type']

        policy_list = [p.strip() for p in policy_filter.split(',') if p.strip()]

        if policy_list and 'policy_name' in filtered_df.columns:
            mask = filtered_df['policy_name'].isin(policy_list)

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # ì¡´ í•„í„° êµ¬í˜„
    if filters.get('source_zone_filter') and filters.get('source_zone_filter').strip():
        zone_filter = filters['source_zone_filter']
        filter_type = filters['source_zone_filter_type']

        zone_list = [z.strip() for z in zone_filter.split(',') if z.strip()]

        if zone_list and 'source_zone' in filtered_df.columns:
            mask = filtered_df['source_zone'].isin(zone_list)

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    if filters.get('destination_zone_filter') and filters.get('destination_zone_filter').strip():
        zone_filter = filters['destination_zone_filter']
        filter_type = filters['destination_zone_filter_type']

        zone_list = [z.strip() for z in zone_filter.split(',') if z.strip()]

        if zone_list and 'destination_zone' in filtered_df.columns:
            mask = filtered_df['destination_zone'].isin(zone_list)

            if filter_type == 'include':
                filtered_df = filtered_df[mask]
            elif filter_type == 'exclude':
                filtered_df = filtered_df[~mask]

    # ë‚ ì§œ í•„í„°
    if filters.get('start_date') and filters.get('end_date'):
        try:
            start_date = pd.to_datetime(filters['start_date'])
            end_date = pd.to_datetime(filters['end_date'])
            
            # end_dateëŠ” í•´ë‹¹ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ì‹œê°„ê¹Œì§€ í¬í•¨
            end_date = end_date + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)

            if 'timestamp' in filtered_df.columns:
                # timestamp ì—´ì˜ íƒ€ì… í™•ì¸
                if not pd.api.types.is_datetime64_any_dtype(filtered_df['timestamp']):
                    filtered_df['timestamp'] = pd.to_datetime(filtered_df['timestamp'])
                
                filtered_df = filtered_df[(filtered_df['timestamp'] >= start_date) &
                                         (filtered_df['timestamp'] <= end_date)]
        except Exception as e:
            logger.error(f"ë‚ ì§œ í•„í„° ì ìš© ì˜¤ë¥˜: {e}")

    # ë…¸ì´ì¦ˆ ì œì™¸ ì˜µì…˜
    if filters.get('exclude_noise'):
        if 'cluster' in filtered_df.columns:
            # í´ëŸ¬ìŠ¤í„°ê°€ -1ì¸ ê²½ìš° ë…¸ì´ì¦ˆ í¬ì¸íŠ¸
            filtered_df = filtered_df[filtered_df['cluster'] != -1]

    return filtered_df

def create_visualizations(analyzer, timestamp):
    """ì‹œê°í™” ìƒì„± (Sankey, 3D ë“±)"""
    visualizations = {}
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ì´ YYYYMMDD_HHMMSSì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³€í™˜
    if '_' not in timestamp:
        # í˜•ì‹ì´ ë‹¤ë¥´ë©´ ì–¸ë”ìŠ¤ì½”ì–´ ì¶”ê°€
        date_part = timestamp[:8]
        time_part = timestamp[8:] if len(timestamp) > 8 else ''
        timestamp = f"{date_part}_{time_part}"
    
    # Sankey ë‹¤ì´ì–´ê·¸ë¨
    sankey_prefix = os.path.join(Config.OUTPUT_DIR, f"traffic_sankey_{timestamp}")
    sankey_files = analyzer.visualize_traffic_sankey(sankey_prefix)
    visualizations['sankey'] = sankey_files

    # êµ­ê°€ë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨
    try:
        country_sankey_prefix = os.path.join(Config.OUTPUT_DIR, f"traffic_sankey_country_{timestamp}")
        country_sankey_files = analyzer.visualize_traffic_sankey_by_country(country_sankey_prefix)
        visualizations['sankey_country'] = country_sankey_files
        logger.info("êµ­ê°€ë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"êµ­ê°€ë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
        visualizations['sankey_country'] = {}
    
    # ASNë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨
    try:
        asn_sankey_prefix = os.path.join(Config.OUTPUT_DIR, f"traffic_sankey_asn_{timestamp}")
        asn_sankey_files = analyzer.visualize_traffic_sankey_by_asn(asn_sankey_prefix)
        visualizations['sankey_asn'] = asn_sankey_files
        logger.info("ASNë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ASNë³„ Sankey ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}")
        visualizations['sankey_asn'] = {}
    
    # 3D ì‹œê°í™”
    viz_prefix = os.path.join(Config.OUTPUT_DIR, f"traffic_3d_interactive_{timestamp}")
    interactive_3d_files = analyzer.visualize_traffic_patterns_3d_interactive(viz_prefix)
    visualizations['interactive_3d'] = interactive_3d_files

    return visualizations

def save_analysis_results(timestamp, data):
    """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    import numpy as np
    from json import JSONEncoder

    # NumPy íƒ€ì…ì„ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ ì¸ì½”ë”
    class NumpyEncoder(JSONEncoder):
        def default(self, obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.bool_):
                return bool(obj)
            return super().default(obj)

    os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

    # ì¥ë¹„ëª… ì •ë³´ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¥ë¹„ëª… ë˜ëŠ” "All" ì‚¬ìš©)
    device_name = "All"
    if 'device_names' in data and data['device_names']:
        device_name = data['device_names'][0]
    
    # ë¶„ì„ ë©”íƒ€ë°ì´í„° ì €ì¥ - ì¥ë¹„ëª… í¬í•¨
    metadata_file = os.path.join(Config.OUTPUT_DIR, f"analysis_{device_name}_{timestamp}.json")
    with open(metadata_file, 'w') as f:
        json.dump(data, f, indent=2, cls=NumpyEncoder)
    
    logger.info(f"Analysis results saved to {metadata_file}")
    return metadata_file
    

def load_analysis_result(timestamp):
    """ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ëª… ë¨¼ì € í™•ì¸
    metadata_file = os.path.join(Config.OUTPUT_DIR, f"analysis_{timestamp}.json")
    
    if os.path.exists(metadata_file):
        with open(metadata_file, 'r') as f:
            return json.load(f)
    
    # ì¼ì¹˜í•˜ëŠ” íŒŒì¼ì´ ì—†ìœ¼ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ ê²€ìƒ‰
    for filename in os.listdir(Config.OUTPUT_DIR):
        if filename.startswith('analysis_') and filename.endswith('.json'):
            # íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ë¶€ë¶„ ì¶”ì¶œ
            file_parts = filename.replace('analysis_', '').replace('.json', '').split('_')
            if len(file_parts) >= 3:  # [ì¥ë¹„ëª…, ë‚ ì§œ, ì‹œê°„] í˜•íƒœ
                file_timestamp = f"{file_parts[-2]}_{file_parts[-1]}"
                if file_timestamp == timestamp:
                    file_path = os.path.join(Config.OUTPUT_DIR, filename)
                    with open(file_path, 'r') as f:
                        return json.load(f)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ë¶€ë¶„ í™•ì¸
    for filename in os.listdir(Config.OUTPUT_DIR):
        if filename.startswith('analysis_') and filename.endswith('.json'):
            if timestamp in filename:
                file_path = os.path.join(Config.OUTPUT_DIR, filename)
                with open(file_path, 'r') as f:
                    return json.load(f)
    
    return None

def get_analyses_list(source_type):
    """íŠ¹ì • íƒ€ì…(upload ë˜ëŠ” syslog)ì˜ ë¶„ì„ ê²°ê³¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    analyses = []
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ë‚´ metadata íŒŒì¼ íƒìƒ‰
    for filename in os.listdir(Config.OUTPUT_DIR):
        if filename.startswith('analysis_') and filename.endswith('.json'):
            file_path = os.path.join(Config.OUTPUT_DIR, filename)
            
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                # source í•„ë“œê°€ ì¼ì¹˜í•˜ëŠ” í•­ëª©ë§Œ ì„ íƒ
                if data.get('source') == source_type:
                    # íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ - ìˆ˜ì •ëœ ë¶€ë¶„
                    # íŒŒì¼ëª… í˜•ì‹: analysis_ì¥ë¹„ëª…_ë‚ ì§œ_ì‹œê°„.json
                    parts = filename.replace('analysis_', '').replace('.json', '').split('_')
                    
                    # íŒŒì¼ëª…ì— ë‚ ì§œì™€ ì‹œê°„ì´ ìˆëŠ” ê²½ìš° (ìµœì†Œ 3ê°œ ë¶€ë¶„ì´ ìˆì–´ì•¼ í•¨)
                    if len(parts) >= 3:
                        # ë§ˆì§€ë§‰ ë‘ ë¶€ë¶„ì„ ë‚ ì§œì™€ ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©
                        date_part = parts[-2]  # YYYYMMDD ë¶€ë¶„
                        time_part = parts[-1]  # HHMMSS ë¶€ë¶„
                        timestamp = f"{date_part}_{time_part}"
                    else:
                        # í˜•ì‹ì´ ë‹¤ë¥¸ ê²½ìš° ì „ì²´ë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì‚¬ìš©
                        timestamp = '_'.join(parts)
                    
                    # ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹¤ì œ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš© (ë” ì •í™•í•¨)
                    if 'timestamp' in data:
                        timestamp = data['timestamp']
                    
                    # ë‚ ì§œì™€ ì‹œê°„ ë¶„ë¦¬
                    timestamp_parts = timestamp.split('_')
                    if len(timestamp_parts) >= 2:
                        date_part = timestamp_parts[0]
                        time_part = timestamp_parts[1]
                    else:
                        date_part = timestamp[:8] if len(timestamp) >= 8 else ""
                        time_part = timestamp[9:] if len(timestamp) >= 15 else ""
                    
                    analyses.append({
                        'timestamp': timestamp,
                        'date': date_part,  # YYYYMMDD ë¶€ë¶„
                        'time': time_part,  # HHMMSS ë¶€ë¶„
                        'policies_count': len(data.get('policies', [])),
                        'file_path': file_path,
                        'log_filenames': data.get('log_filenames', []),
                        'device_names': data.get('device_names', []),
                        'filters_applied': data.get('filters_applied', False),
                        'total_records': data.get('total_log_records', 0),
                        'filtered_records': data.get('filtered_log_records', 0),
                        'analysis_type': data.get('analysis_type', 'auto'),
                        'source_filename': data.get('source_filename', '')
                    })
            except Exception as e:
                logger.error(f"ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
                continue
    
    # ìµœì‹  ë¶„ì„ ê²°ê³¼ê°€ ë¨¼ì € ì˜¤ë„ë¡ ì •ë ¬
    analyses.sort(key=lambda x: x['timestamp'], reverse=True)
    
    return analyses

def get_logs_list(source_type):
    """íŠ¹ì • íƒ€ì…(upload ë˜ëŠ” syslog)ì˜ ë¡œê·¸ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    logs = []
    
    if source_type == 'upload':
        log_dir = Config.UPLOAD_DIR
    else:  # syslog
        log_dir = Config.LOGS_DIR
    
    # ë””ë ‰í† ë¦¬ íƒìƒ‰
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.endswith('.log'):
                file_path = os.path.join(log_dir, filename)
                
                # íŒŒì¼ ì •ë³´
                stat = os.stat(file_path)
                logs.append({
                    'filename': filename,
                    'size': stat.st_size,
                    'modified': datetime.fromtimestamp(stat.st_mtime),
                    'file_path': file_path
                })
    
    # ìµœì‹  íŒŒì¼ì´ ë¨¼ì € ì˜¤ë„ë¡ ì •ë ¬
    logs.sort(key=lambda x: x['modified'], reverse=True)
    
    return logs

def start_syslog_server():
    """Syslog ì„œë²„ ì‹œì‘"""
    import threading
    
    if global_state['is_syslog_running']:
        return
    
    config = global_state['syslog_config']
    
    # ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    server = SyslogServer(
        host=config['host'],
        port=config['port'],
        log_dir=Config.LOGS_DIR,
        analysis_interval=config['interval'],
        output_dir=Config.OUTPUT_DIR,
        device_filter=config['device_filter'],
        device_filter_type=config['device_filter_type'],
        regex_filter=config['regex_filter'],
        regex_filter_type=config['regex_filter_type']
    )
    
    # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    def run_server():
        server.start()
    
    thread = threading.Thread(target=run_server)
    thread.daemon = True
    thread.start()
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state['syslog_server'] = server
    global_state['syslog_thread'] = thread
    global_state['is_syslog_running'] = True
    
    logger.info(f"Syslog server started on {config['host']}:{config['port']}")

def stop_syslog_server():
    """Syslog ì„œë²„ ì¤‘ì§€"""
    if not global_state['is_syslog_running']:
        return
    
    # ì„œë²„ ì¤‘ì§€
    if global_state['syslog_server']:
        global_state['syslog_server'].running = False
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    global_state['is_syslog_running'] = False
    global_state['syslog_server'] = None
    global_state['syslog_thread'] = None
    
    logger.info("Syslog server stopped")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="MLê¸°ë°˜ ë°©í™”ë²½ ì •ì±… ì¶”ì²œ ì‹œìŠ¤í…œ"
    )
    
    parser.add_argument('--host', default='0.0.0.0', help='ì›¹ ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=14000, help='ì›¹ ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: 14000)')
    parser.add_argument('--ssl-cert', default='ssl/cert.pem', help='SSL ì¸ì¦ì„œ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--ssl-key', default='ssl/key.pem', help='SSL í‚¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”')
    
    args = parser.parse_args()
    
    # SSL ì²˜ë¦¬
    ssl_context = None
    if os.path.exists(args.ssl_cert) and os.path.exists(args.ssl_key):
        try:
            # SSL ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            ssl_context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
            ssl_context.load_cert_chain(certfile=args.ssl_cert, keyfile=args.ssl_key)
            logger.info("SSL ì¸ì¦ì„œ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            logger.error(f"SSL ì„¤ì • ì˜¤ë¥˜: {e}")
            ssl_context = None
    
    if ssl_context:
        # HTTPS ì„œë²„
        http_server = WSGIServer((args.host, args.port), app, ssl_context=ssl_context)
        logger.info(f"HTTPS ì„œë²„ê°€ {args.host}:{args.port}ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤.")
    else:
        # HTTP ì„œë²„ (SSL ì—†ìŒ)
        http_server = WSGIServer((args.host, args.port), app)
        logger.warning(f"SSL ì¸ì¦ì„œê°€ ì—†ìŠµë‹ˆë‹¤. HTTP ì„œë²„ê°€ {args.host}:{args.port}ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤.")
    
    try:
        http_server.serve_forever()
    except KeyboardInterrupt:
        logger.info("ì„œë²„ê°€ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    # ì‹¤í–‰ ì¤‘ì¸ Syslog ì„œë²„ ì¢…ë£Œ
    if global_state['is_syslog_running']:
        stop_syslog_server()

if __name__ == "__main__":
    main()
